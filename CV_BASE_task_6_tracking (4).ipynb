{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d01a410-17cc-4376-b008-9f8cbedb2199",
      "metadata": {
        "id": "8d01a410-17cc-4376-b008-9f8cbedb2199"
      },
      "outputs": [],
      "source": [
        "# Продолжайте развивать генератор данных.\n",
        "# Решите задачу трекинга объектов.\n",
        "# Этап 1. Генератор последовательности кадров с потоком клеток, перемещающихся \"слева - направо\".\n",
        "#  - сгенерировать последовательность кадров в 10 секунд (итого - примерно 240 кдаров)\n",
        "# - первичное положение клеток - случайный пиксель\n",
        "# - при достижении границы изображения объект прекращает свое существование\n",
        "# - пусть генератор пути клеток позволяет перемещать клетку по синусоиде  y(x(t) ) = ax+b + c * sin( omega *x) + eps_noise\n",
        "# - a,b,c omega - случайно сгенерированные значения для данной клетки  eps_noise - случайное значение для каждой секунды\n",
        "# - a,b,c omega - случайно сгенерированные значения для данной клетки\n",
        "# - 10 секунду - 10 отсчетов времени t,  положение между кажром 0 и кадром 24 интерполируется при помощи линейной интерполяции по формуле:\n",
        "# - выполнить то же самое, только зависимость не T(z),как в примере, а y(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f85748-ca4b-4efd-ae4d-fcaa5e776eea",
      "metadata": {
        "id": "b2f85748-ca4b-4efd-ae4d-fcaa5e776eea"
      },
      "outputs": [],
      "source": [
        "# Этап 2. Трекинг объектов.\n",
        "# Используя пример, приведенный в лекции про трекинг, решить задачу трекинга объектов\n",
        "# Пути (положения) объктов на каждом кадре сохранить в файл.\n",
        "# Визуализировать траектории объектов на изображении."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CellAnimationGenerator:\n",
        "    def __init__(self):\n",
        "        self.background_images = []\n",
        "        self.cell_images = []\n",
        "\n",
        "    def load_assets(self, bg_folder=\"background\", cell_folder=\"cells\"):\n",
        "        def load_img_folder(folder):\n",
        "            return [cv2.imread(os.path.join(folder, f))\n",
        "                   for f in os.listdir(folder)\n",
        "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        self.background_images = load_img_folder(bg_folder)\n",
        "        self.cell_images = load_img_folder(cell_folder)\n",
        "\n",
        "        if not self.background_images or not self.cell_images:\n",
        "            raise ValueError(\"Missing image assets!\")\n",
        "\n",
        "    def create_composite_background(self, size=(450, 450)):\n",
        "        composite = np.zeros((*size, 3), dtype=np.uint8)\n",
        "        tile_size = size[0] // 3\n",
        "\n",
        "        for i in range(0, size[0], tile_size):\n",
        "            for j in range(0, size[1], tile_size):\n",
        "                if self.background_images:\n",
        "                    tile = random.choice(self.background_images)\n",
        "                    composite[i:i+tile_size, j:j+tile_size] = cv2.resize(tile, (tile_size, tile_size))\n",
        "        return composite\n",
        "\n",
        "    def render_cell(self, canvas, cell_img, position, blur_radius=21):\n",
        "        x, y = position\n",
        "        h, w = canvas.shape[:2]\n",
        "        cell_h, cell_w = cell_img.shape[:2]\n",
        "\n",
        "        # Calculate overlapping regions\n",
        "        canvas_x1, canvas_x2 = max(0, x), min(w, x + cell_w)\n",
        "        canvas_y1, canvas_y2 = max(0, y), min(h, y + cell_h)\n",
        "\n",
        "        cell_x1 = max(0, -x)\n",
        "        cell_x2 = cell_w - max(0, x + cell_w - w)\n",
        "        cell_y1 = max(0, -y)\n",
        "        cell_y2 = cell_h - max(0, y + cell_h - h)\n",
        "\n",
        "        # Create alpha mask\n",
        "        mask = np.zeros((cell_y2-cell_y1, cell_x2-cell_x1), dtype=np.float32)\n",
        "        center = ((cell_x2-cell_x1)//2, (cell_y2-cell_y1)//2)\n",
        "        radius = min(center[0], center[1])\n",
        "        cv2.circle(mask, center, radius, 1, -1)\n",
        "        mask = cv2.GaussianBlur(mask, (blur_radius, blur_radius), 0)[..., None]\n",
        "\n",
        "        # Blend images\n",
        "        canvas[canvas_y1:canvas_y2, canvas_x1:canvas_x2] = (\n",
        "            canvas[canvas_y1:canvas_y2, canvas_x1:canvas_x2] * (1 - mask) +\n",
        "            cell_img[cell_y1:cell_y2, cell_x1:cell_x2] * mask\n",
        "        ).astype(np.uint8)\n",
        "\n",
        "        return canvas\n",
        "\n",
        "class CellMotionSimulator:\n",
        "    def __init__(self, canvas_size):\n",
        "        self.width, self.height = canvas_size\n",
        "        self.phase_offset = random.uniform(0, math.pi*2)\n",
        "        self.wave_frequency = random.uniform(0.03, 0.08)\n",
        "        self.velocity = random.uniform(8, 12)\n",
        "        self.amplitude = random.uniform(10, 30)\n",
        "        self.noise = {\n",
        "            'phase': random.uniform(0, math.pi*2),\n",
        "            'frequency': random.uniform(0.5, 2.0),\n",
        "            'amplitude': random.uniform(1, 3)\n",
        "        }\n",
        "\n",
        "        self.x = random.randint(-50, 20)\n",
        "        self.y = random.randint(0, self.height)\n",
        "        self.origin_y = self.y\n",
        "\n",
        "    def update_position(self, delta_time):\n",
        "        self.x += self.velocity * delta_time\n",
        "\n",
        "        noise_component = math.sin(self.noise['phase']) * self.noise['amplitude']\n",
        "        self.noise['phase'] += self.noise['frequency'] * delta_time\n",
        "\n",
        "        wave_component = self.amplitude * math.sin(self.wave_frequency * self.x)\n",
        "\n",
        "        self.y = self.origin_y + wave_component + noise_component\n",
        "        self.y = np.clip(self.y, 0, self.height - 1)\n",
        "\n",
        "        return self.x < self.width + 100  # Check if still visible\n",
        "\n",
        "class CellTracker:\n",
        "    def __init__(self):\n",
        "        self.trajectories = {}\n",
        "        self.current_id = 0\n",
        "        self.colors = np.random.randint(0, 255, (1000, 3))\n",
        "\n",
        "    def process_detections(self, current_detections):\n",
        "        if not self.trajectories:\n",
        "            for det in current_detections:\n",
        "                self._init_track(det)\n",
        "            return self.trajectories\n",
        "\n",
        "        matched = set()\n",
        "        active_tracks = {}\n",
        "\n",
        "        for track_id, track in self.trajectories.items():\n",
        "            last_pos = track['path'][-1]\n",
        "            closest = self._find_closest(last_pos, current_detections, matched)\n",
        "\n",
        "            if closest is not None:\n",
        "                matched.add(closest)\n",
        "                track['path'].append(self._get_center(current_detections[closest]))\n",
        "                track['missed'] = 0\n",
        "                active_tracks[track_id] = track\n",
        "\n",
        "        # Handle new detections\n",
        "        for i, det in enumerate(current_detections):\n",
        "            if i not in matched:\n",
        "                self._init_track(det)\n",
        "\n",
        "        return self.trajectories\n",
        "\n",
        "    def _init_track(self, detection):\n",
        "        self.trajectories[self.current_id] = {\n",
        "            'path': [self._get_center(detection)],\n",
        "            'missed': 0\n",
        "        }\n",
        "        self.current_id += 1\n",
        "\n",
        "    def _find_closest(self, reference, detections, excluded):\n",
        "        min_dist, best_match = float('inf'), None\n",
        "\n",
        "        for i, det in enumerate(detections):\n",
        "            if i in excluded:\n",
        "                continue\n",
        "\n",
        "            dist = np.linalg.norm(np.array(reference) - np.array(self._get_center(det)))\n",
        "            if dist < 25 and dist < min_dist:\n",
        "                min_dist, best_match = dist, i\n",
        "\n",
        "        return best_match\n",
        "\n",
        "    def _get_center(self, bbox):\n",
        "        x, y, w, h = bbox\n",
        "        return (x + w//2, y + h//2)\n",
        "\n",
        "def generate_animation(output_file=\"cell_animation.mp4\", duration=10, fps=24):\n",
        "    generator = CellAnimationGenerator()\n",
        "    generator.load_assets()\n",
        "\n",
        "    canvas_size = (450, 450)\n",
        "    background = generator.create_composite_background(canvas_size)\n",
        "    video_writer = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'mp4v'), fps, canvas_size)\n",
        "\n",
        "    active_cells = []\n",
        "    total_frames = duration * fps\n",
        "\n",
        "    for frame_idx in tqdm(range(total_frames), desc=\"Generating animation\"):\n",
        "        frame = background.copy()\n",
        "\n",
        "        # Add new cells periodically\n",
        "        if len(active_cells) < 8 and (frame_idx % 20 == 0 or len(active_cells) < 2):\n",
        "            cell_img = random.choice(generator.cell_images)\n",
        "            size = random.randint(40, 80)\n",
        "            active_cells.append({\n",
        "                'simulator': CellMotionSimulator(canvas_size),\n",
        "                'image': cv2.resize(cell_img, (size, size))\n",
        "            })\n",
        "\n",
        "        # Update and render cells\n",
        "        for cell in active_cells[:]:\n",
        "            if not cell['simulator'].update_position(1/fps):\n",
        "                active_cells.remove(cell)\n",
        "                continue\n",
        "\n",
        "            position = (int(cell['simulator'].x), int(cell['simulator'].y))\n",
        "            frame = generator.render_cell(frame, cell['image'], position)\n",
        "\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    video_writer.release()\n",
        "    print(f\"Animation saved to {output_file}\")\n",
        "\n",
        "def analyze_cell_movement(video_path):\n",
        "    capture = cv2.VideoCapture(video_path)\n",
        "    tracker = CellTracker()\n",
        "    processed_frames = []\n",
        "\n",
        "    while capture.isOpened():\n",
        "        success, frame = capture.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Detection and tracking\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
        "        threshold = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                        cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "        contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        detections = []\n",
        "\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if 100 < area < 3000:\n",
        "                perimeter = cv2.arcLength(contour, True)\n",
        "                if perimeter > 0:\n",
        "                    circularity = 4 * np.pi * area / (perimeter ** 2)\n",
        "                    if 0.7 < circularity < 1.3:\n",
        "                        x, y, w, h = cv2.boundingRect(contour)\n",
        "                        detections.append((x, y, w, h))\n",
        "\n",
        "        tracker.process_detections(detections)\n",
        "\n",
        "        # Visualization\n",
        "        display = frame.copy()\n",
        "        for track_id, data in tracker.trajectories.items():\n",
        "            color = tracker.colors[track_id % len(tracker.colors)].tolist()\n",
        "            path = data['path']\n",
        "\n",
        "            for i in range(1, len(path)):\n",
        "                cv2.line(display, path[i-1], path[i], color, 2)\n",
        "\n",
        "            if path:\n",
        "                cv2.circle(display, path[-1], 5, color, -1)\n",
        "                cv2.putText(display, str(track_id), (path[-1][0]+10, path[-1][1]),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "        processed_frames.append(display)\n",
        "\n",
        "    capture.release()\n",
        "\n",
        "    # Save results\n",
        "    os.makedirs(\"analysis_results\", exist_ok=True)\n",
        "\n",
        "    # Save trajectory data\n",
        "    with open(\"analysis_results/trajectories.csv\", \"w\") as f:\n",
        "        f.write(\"track_id,frame,x,y\\n\")\n",
        "        for track_id, data in tracker.trajectories.items():\n",
        "            for frame_num, (x, y) in enumerate(data['path']):\n",
        "                f.write(f\"{track_id},{frame_num},{x},{y}\\n\")\n",
        "\n",
        "    # Visualize trajectories\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for track_id, data in tracker.trajectories.items():\n",
        "        if len(data['path']) > 10:\n",
        "            xs, ys = zip(*data['path'])\n",
        "            plt.plot(xs, ys, label=f'Cell {track_id}')\n",
        "\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.legend()\n",
        "    plt.title(\"Cell Movement Analysis\")\n",
        "    plt.savefig(\"analysis_results/trajectories_plot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(\"Analysis complete. Results saved in 'analysis_results' folder.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_animation()\n",
        "\n",
        "    analyze_cell_movement(\"cell_animation.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVG84azaPGS8",
        "outputId": "17ec1b31-b257-4a54-cf7c-57b114afa478"
      },
      "id": "GVG84azaPGS8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating animation: 100%|██████████| 240/240 [00:01<00:00, 203.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Animation saved to cell_animation.mp4\n",
            "Analysis complete. Results saved in 'analysis_results' folder.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}